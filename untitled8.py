# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ffge5obCOJ_AfQKHI9N_UB4-1n5kSx7u
"""

!gdown 'https://isic-challenge-data.s3.amazonaws.com/2020/ISIC_2020_Training_JPEG.zip'

!gdown 'https://isic-challenge-data.s3.amazonaws.com/2020/ISIC_2020_Training_GroundTruth.csv'

!unzip ISIC_2020_Training_JPEG.zip

!rm ISIC_2020_Training_JPEG.zip

!pip install livelossplot

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import cv2
import PIL
from IPython.display import Image, display
from keras.applications.vgg16 import VGG16,preprocess_input
# Plotly for the interactive viewer (see last section)
import plotly.graph_objs as go
import plotly.graph_objects as go
from sklearn.metrics import cohen_kappa_score
from sklearn.model_selection import train_test_split
from keras.models import Sequential, Model,load_model
from keras.applications.vgg16 import VGG16,preprocess_input
from keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten,BatchNormalization,Activation
from keras.layers import GlobalMaxPooling2D
from keras.models import Model
from tensorflow.keras.optimizers import Adam, SGD, RMSprop
from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import gc
import skimage.io
import tensorflow as tf
import tensorflow.keras.applications.resnet50
import matplotlib.pyplot as plt
from tensorflow.python.keras import backend as K
from livelossplot import PlotLossesKeras
from sklearn import metrics

train_dir='./train/'
test_dir='./train/'
train=pd.read_csv('./train.csv')
# test=pd.read_csv('./test.csv')

train.head()

train['target'].value_counts()

dist=train['target'].value_counts()
print("Benign cases are",(32542/(32542+584))*100)

new=train.drop(labels=['image_name','patient_id','sex','age_approx','anatom_site_general_challenge','target'],axis=1)
pd.crosstab(new['diagnosis'].values,new['benign_malignant'])

df_0=train[train['target']==0]
df_1=train[train['target']==1]
train=pd.concat([df_0,df_1])
train=train.reset_index()

labels_x=[]
labels_y=[]
data=[]
test_data=[]
benign_cnt = 0
malignant_cnt = 0
for i in range(train.shape[0]):
    if train['target'].iloc[i] == 0:
      benign_cnt += 1
      if benign_cnt % 10 == 0:
        test_data.append(test_dir + train['image_name'].iloc[i]+'.jpg')
        labels_y.append(0)
      else:
        data.append(train_dir + train['image_name'].iloc[i]+'.jpg')
        labels_x.append(0)
    else:
      malignant_cnt += 1
      if malignant_cnt % 10 == 0:
        test_data.append(test_dir + train['image_name'].iloc[i]+'.jpg')
        labels_y.append(1)
      else:
        data.append(train_dir + train['image_name'].iloc[i]+'.jpg')
        labels_x.append(1)

df=pd.DataFrame(data)
df.columns=['images']
df['target']=labels_x

df_test=pd.DataFrame(test_data)
df_test.columns=['images']
df_test['target']=labels_y



tf.cast(labels_x, tf.float32)
tf.cast(labels_y, tf.float32)

X_train, X_val, y_train, y_val = train_test_split(df['images'],df['target'], test_size=0.2, random_state=1234)

train=pd.DataFrame(X_train)
train.columns=['images']
train['target']=y_train

validation=pd.DataFrame(X_val)
validation.columns=['images']
validation['target']=y_val

train_datagen = ImageDataGenerator(rescale=1./255,rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,horizontal_flip=True)
val_datagen=ImageDataGenerator(rescale=1./255)
train_generator = train_datagen.flow_from_dataframe(
    train,
    x_col='images',
    y_col='target',
    target_size=(224, 224),
    batch_size=8,
    shuffle=True,
    class_mode='raw')

validation_generator = val_datagen.flow_from_dataframe(
    validation,
    x_col='images',
    y_col='target',
    target_size=(224, 224),
    shuffle=False,
    batch_size=8,
    class_mode='raw')

def vgg16_model( num_classes=None):

    model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
    x=Flatten()(model.output)
    output=Dense(1,activation='sigmoid')(x) # because we have to predict the AUC
    model=Model(model.input,output)
    
    return model

vgg_conv=vgg16_model(1)

def focal_loss(alpha=0.25,gamma=2.0):
    def focal_crossentropy(y_true, y_pred):
        y_true = tf.cast(y_true, tf.float32)
        bce = K.binary_crossentropy(y_true, y_pred)
        
        y_pred = K.clip(y_pred, K.epsilon(), 1.- K.epsilon())
        p_t = (y_true*y_pred) + ((1-y_true)*(1-y_pred))
        
        alpha_factor = 1
        modulating_factor = 1

        alpha_factor = y_true*alpha + ((1-alpha)*(1-y_true))
        modulating_factor = K.pow((1-p_t), gamma)

        # compute the final loss and return
        return K.mean(alpha_factor*modulating_factor*bce, axis=-1)
    return focal_crossentropy

opt = Adam(lr=1e-5)
vgg_conv.compile(loss=focal_loss(), metrics=[tf.keras.metrics.AUC()],optimizer=opt)

nb_epochs = 3
batch_size= 64
nb_train_steps = train.shape[0]//batch_size
nb_val_steps = validation.shape[0]//batch_size
print("Number of training and validation steps: {} and {}".format(nb_train_steps,nb_val_steps))

cb=[PlotLossesKeras()]
vgg_conv.fit_generator(
    train_generator,
    steps_per_epoch=nb_train_steps,
    epochs=nb_epochs,
    validation_data=validation_generator,
    callbacks=cb,
    validation_steps=nb_val_steps)

target=[]
df_t=[]
for i in range(len(df_test['images'])):
    img=cv2.imread(str(df_test['images'][i]))
    try:
      img = cv2.resize(img, (224,224))
      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
      img = img.astype(np.float32)/255.
      img=np.reshape(img,(1,224,224,3))
      prediction=vgg_conv.predict(img)
      target.append(prediction[0][0])
      df_t.append(labels_y[i])
    except:
      pass

targett = []
for t in target:
  if t > 0.29:
    targett.append(1)
  else:
    targett.append(0)

matrix = metrics.confusion_matrix(df_t, targett)

matrix

tn, fn, fp, tp = matrix[0, 0], matrix[0, 1], matrix[1, 0], matrix[1, 1]

accuracy = (tp + tn)/(tp + tn + fp + fn)
recall = tp/(tp + fn)
precision = tp/(tp+fp)
f = 2*(precision*recall)/(precision+recall)

print('accuracy: ', accuracy)
print('recall: ', recall)
print('precision: ', precision)
print('f1 score: ', f)

def vgg19_model( num_classes=None):

    model = tf.keras.applications.vgg19.VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
    x=Flatten()(model.output)
    output=Dense(1,activation='sigmoid')(x) # because we have to predict the AUC
    model=Model(model.input,output)
    
    return model

vgg19_conv=vgg19_model(1)

opt = Adam(lr=1e-5)
vgg19_conv.compile(loss=focal_loss(), metrics=[tf.keras.metrics.AUC()],optimizer=opt)

from PIL import ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True


nb_epochs = 3
batch_size= 64
nb_train_steps = train.shape[0]//batch_size
nb_val_steps = validation.shape[0]//batch_size
print("Number of training and validation steps: {} and {}".format(nb_train_steps,nb_val_steps))

cb=[PlotLossesKeras()]
vgg19_conv.fit_generator(
    train_generator,
    steps_per_epoch=nb_train_steps,
    epochs=nb_epochs,
    validation_data=validation_generator,
    callbacks=cb,
    validation_steps=nb_val_steps)

target=[]
df_t=[]
for i in range(len(df_test['images'])):
    print(df_test['images'][i])
    img=cv2.imread(str(df_test['images'][i]))
    try:
      img = cv2.resize(img, (224,224))
      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
      img = img.astype(np.float32)/255.
      img=np.reshape(img,(1,224,224,3))
      prediction=vgg19_conv.predict(img)
      target.append(prediction[0][0])
      df_t.append(labels_y[i])
    except:
      pass

targett = []
for t in target:
  if t > 0.70:
    targett.append(1)
  else:
    targett.append(0)

matrix = metrics.confusion_matrix(df_t, targett)

matrix

tn, fn, fp, tp = matrix[0, 0], matrix[0, 1], matrix[1, 0], matrix[1, 1]

accuracy = (tp + tn)/(tp + tn + fp + fn)
recall = tp/(tp + fn)
precision = tp/(tp+fp)
f = 2*(precision*recall)/(precision+recall)

print('accuracy: ', accuracy)
print('recall: ', recall)
print('precision: ', precision)
print('f1 score: ', f)



def inceptionv3_model( num_classes=None):

    model = tf.keras.applications.inception_v3.InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
    x=Flatten()(model.output)
    output=Dense(1,activation='sigmoid')(x) # because we have to predict the AUC
    model=Model(model.input,output)
    
    return model

inceptionv3_conv=inceptionv3_model(1)

opt = Adam(lr=1e-5)
inceptionv3_conv.compile(loss=focal_loss(), metrics=[tf.keras.metrics.AUC()],optimizer=opt)

from PIL import ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True


nb_epochs = 3
batch_size= 64
nb_train_steps = train.shape[0]//batch_size
nb_val_steps = validation.shape[0]//batch_size
print("Number of training and validation steps: {} and {}".format(nb_train_steps,nb_val_steps))

cb=[PlotLossesKeras()]
inceptionv3_conv.fit_generator(
    train_generator,
    steps_per_epoch=nb_train_steps,
    epochs=nb_epochs,
    validation_data=validation_generator,
    callbacks=cb,
    validation_steps=nb_val_steps)

target=[]
df_t=[]
for i in range(len(df_test['images'])):
    print(df_test['images'][i])
    img=cv2.imread(str(df_test['images'][i]))
    try:
      img = cv2.resize(img, (224,224))
      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
      img = img.astype(np.float32)/255.
      img=np.reshape(img,(1,224,224,3))
      prediction=inceptionv3_conv.predict(img)
      target.append(prediction[0][0])
      df_t.append(labels_y[i])
    except:
      pass

targett = []
for t in target:
  if t > 0.33:
    targett.append(1)
  else:
    targett.append(0)

matrix = metrics.confusion_matrix(df_t, targett)

matrix

tn, fn, fp, tp = matrix[0, 0], matrix[0, 1], matrix[1, 0], matrix[1, 1]

accuracy = (tp + tn)/(tp + tn + fp + fn)
recall = tp/(tp + fn)
precision = tp/(tp+fp)
f = 2*(precision*recall)/(precision+recall)

print('accuracy: ', accuracy)
print('recall: ', recall)
print('precision: ', precision)
print('f1 score: ', f)

